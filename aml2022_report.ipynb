{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "aml2022_report.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/singwang-cn/Neural-Network/blob/master/aml2022_report.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Advanced Machine Learning (2022) Final Report Assignment\n",
        "\n",
        "Answer Questions 1 to 4 (either in Japanese or English). Submit a report in either PDF (.pdf) or JupyterNotebook (.ipynb) format.\n",
        "\n",
        "## Question 1 (50 points)\n",
        "\n",
        "Consider a convolutional neural network (CNN) that predicts a label $\\hat{y} \\in \\{0, 1\\}$ for a given sentence $\\boldsymbol{X} \\in \\mathbb{R}^{d \\times T}$. Here, a sentence is represented by a matrix $\\boldsymbol{X} = (\\boldsymbol{x}_1, \\boldsymbol{x}_2, \\dots, \\boldsymbol{x}_T)$ consisting of a concatenation of $T$ word embeddings, $\\boldsymbol{x}_1, \\boldsymbol{x}_2, \\dots, \\boldsymbol{x}_T \\in \\mathbb{R}^d$, where $d$ is the size of word embeddings, and $T$ is the number of words in the sentence.\n",
        "\n",
        "These equations define the whole architecture of the CNN.\n",
        "\n",
        "\\begin{align}\n",
        "\\hat{y} &= \\begin{cases}\n",
        "1 & (0.5 < p) \\\\\n",
        "0 & (p \\leq 0.5)\n",
        "\\end{cases} \\\\\n",
        "p &= \\sigma(\\boldsymbol{v}^\\top \\boldsymbol{s}) \\\\\n",
        "\\boldsymbol{s} &= \\max(\\boldsymbol{c}_1, \\dots, \\boldsymbol{c}_{T-\\delta+1}) \\\\\n",
        "\\boldsymbol{c}_t &= {\\rm ReLU}(\\boldsymbol{W} \\boldsymbol{x}_{t:t+\\delta-1} + \\boldsymbol{b}) & (\\forall t \\in \\{1, \\dots, T-\\delta+1\\}) \\\\\n",
        "\\boldsymbol{x}_{t:t+\\delta-1} &= \\boldsymbol{x}_{t} \\oplus \\boldsymbol{x}_{t+1} \\oplus \\dots \\oplus \\boldsymbol{x}_{t+\\delta-1}\n",
        "\\end{align}\n",
        "\n",
        "Here:\n",
        "\n",
        "+ $\\boldsymbol{W} \\in \\mathbb{R}^{m \\times \\delta d}$, $\\boldsymbol{b} \\in \\mathbb{R}^m, \\boldsymbol{v} \\in \\mathbb{R}^m$ are the model parameters;\n",
        "+ $m$ denotes the number of output channels of the CNN;\n",
        "+ $\\delta$ denotes the width (kernel size) of the convolution;\n",
        "+ $\\sigma(\\cdot)$ denotes the standard sigmoid function;\n",
        "+ $\\max(\\cdot)$ presents the max pooling operation;\n",
        "+ ${\\rm ReLU}(\\cdot)$ denotes the ReLU activation function;\n",
        "+ $\\oplus$ presents a concatenation of vectors.\n",
        "\n",
        "Setting the hyperparameters $d=3, m=2, \\delta=2$, we initialize the model parameters as follows.\n",
        "\n",
        "\\begin{align}\n",
        "\\boldsymbol{W} &= \\begin{pmatrix}\n",
        "-3 & -2 & -1 & -1 & -2 & -3 \\\\\n",
        "3 & 2 & 3 & 2 & 3 & 2\n",
        "\\end{pmatrix} \\\\\n",
        "\\boldsymbol{b} &= \\begin{pmatrix}\n",
        "-0.2 \\\\ 0.1\n",
        "\\end{pmatrix} \\\\\n",
        "\\boldsymbol{v} &= \\begin{pmatrix}\n",
        "-1 \\\\ 2\n",
        "\\end{pmatrix}\n",
        "\\end{align}\n",
        "\n",
        "Suppose that we give a negative ($y=0$) training instance with the sentence ($T = 5$),\n",
        "\n",
        "\\begin{align}\n",
        "\\boldsymbol{X} &= \\begin{pmatrix}\n",
        "-0.3 & 0 & 0.1 & 0 & 0 \\\\\n",
        "-0.2 & -0.1 & 0 & 0.1 & 0 \\\\\n",
        "-0.1 & -0.2 & 0.1 & 0 & 0.1\n",
        "\\end{pmatrix} ,\n",
        "\\end{align}\n",
        "to the CNN model, and answer the following questions.\n",
        "\n",
        "**(1)** Find the value of the vector $\\boldsymbol{x}_{3:4}$."
      ],
      "metadata": {
        "id": "-z-I39fBi1MD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F"
      ],
      "metadata": {
        "id": "uec36GNAyNdz"
      },
      "execution_count": 238,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d = 3\n",
        "m = 2\n",
        "delta = 2 \n",
        "\n",
        "W = np.array([[-3, 3],\n",
        "              [-2, 2],\n",
        "              [-1, 3],\n",
        "              [-1, 2],\n",
        "              [-2, 3],\n",
        "              [-3, 2]])\n",
        "b = np.array([-0.2, 0.1])\n",
        "v = np.array([-1., 2.])\n",
        "X = np.array([[-0.3, -0.2, -0.1],\n",
        "              [0, -0.1, -0.2],\n",
        "              [0.1, 0, 0.1],\n",
        "              [0, 0.1, 0],\n",
        "              [0, 0, 0.1]])"
      ],
      "metadata": {
        "id": "oIdoAZi0zfv8"
      },
      "execution_count": 239,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Answer (1)\n",
        "x_34 = np.concatenate(X[2:4], axis=0)\n",
        "print('x_(3:4) = ', x_34)"
      ],
      "metadata": {
        "id": "X92NXbvx4HVg",
        "outputId": "b8df6d77-613e-4fc9-ac14-458e2c84f663",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 240,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_(3:4) =  [0.1 0.  0.1 0.  0.1 0. ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**(2)** Find the values of the hidden vectors $\\boldsymbol{c}_1, \\boldsymbol{c}_2, \\boldsymbol{c}_3, \\boldsymbol{c}_4$."
      ],
      "metadata": {
        "id": "7XCf-KoPyOfp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "C = F.relu(torch.Tensor(np.concatenate((X[:-(delta-1)], X[(delta-1):]), axis=1).dot(W)+b))"
      ],
      "metadata": {
        "id": "1jrThGYWr47E"
      },
      "execution_count": 241,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Answer (2)\n",
        "for i in range(C.shape[0]):\n",
        "  print('c[' + str(i+1) + '] =', C[i].numpy())"
      ],
      "metadata": {
        "id": "DqOeGvGs-N1f",
        "outputId": "380973ec-3bda-47dc-bdcf-8334859131ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 242,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "c[1] = [2. 0.]\n",
            "c[2] = [0. 0.]\n",
            "c[3] = [0. 1.]\n",
            "c[4] = [0.  0.5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**(3)** Find the value of the vector $\\boldsymbol{s}$.\n"
      ],
      "metadata": {
        "id": "kVFqVPWPyQ58"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Answer (3)\n",
        "s = C.numpy().reshape((int((C.shape[0]*C.shape[1] / (delta*delta))) ,delta*delta)).max(axis=1)\n",
        "print('s =', s)"
      ],
      "metadata": {
        "id": "Vt3UQqqAyTVj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a983257c-2304-4516-b1bf-992873bed259"
      },
      "execution_count": 243,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "s = [2. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**(4)** Find the value of $p$."
      ],
      "metadata": {
        "id": "Kt26e_TSyT6W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid_func(x):\n",
        "  return 1 / (1 + np.exp(-x))"
      ],
      "metadata": {
        "id": "U4g6j4L3y635"
      },
      "execution_count": 244,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Answer (4)\n",
        "p = sigmoid_func(v.dot(s))\n",
        "print('p =', p)"
      ],
      "metadata": {
        "id": "VDBZLZSnX7sS",
        "outputId": "257215fe-363c-4d05-b731-563fec143341",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 245,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p = 0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**(5)** Write the formula of the binary cross-entropy loss between the correct label $y$ and the probability estimate $p$."
      ],
      "metadata": {
        "id": "fUh6ZlAqyWRE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer (5)\n",
        "\n",
        "\\begin{equation*}\n",
        "Loss = -\\frac{1}{N}\\sum_{i=1}^N y_i\\log p_i+(1-y_i)\\log (1-p_i)\n",
        "\\end{equation*}\n",
        "where $N$ is the number of data, $y_i$ is the label and $p$ is the predicted value."
      ],
      "metadata": {
        "id": "6CaayxkzbQZd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def bceloss_func(y, p):\n",
        "  n = 1\n",
        "  if type(y) != 'int':\n",
        "    n = y.shape[0]\n",
        "  loss_array = y*np.log(p) + (1-y)*np.log(1-p)\n",
        "  return -loss_array.sum(axis=0) / n"
      ],
      "metadata": {
        "id": "QdCPWs4UyV9b"
      },
      "execution_count": 246,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**(6)** Compute the loss value by using the formula of (5) for the training instance."
      ],
      "metadata": {
        "id": "p9WQToWfyYuj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Answer (6)\n",
        "loss = bceloss_func(np.array([0]), p)\n",
        "print('loss =',loss)"
      ],
      "metadata": {
        "id": "LsFTKdK3zpYC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e188cea-b491-4c84-b9be-36c464081f67"
      },
      "execution_count": 253,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss = 0.6931471805599453\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**(7)** Compute the gradient of the loss function with respect to $\\boldsymbol{v}$ for the training instance."
      ],
      "metadata": {
        "id": "6b03t2amzpz5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class build_model(nn.Module):\n",
        "  def __init__(self, W, b, v, kernel_size=2, stride=2) -> None:\n",
        "    super().__init__()\n",
        "    \n",
        "    self.linear1 = nn.Linear(6, 2, bias=True)\n",
        "    self.linear1.weight.data = torch.Tensor(W.T)\n",
        "    self.linear1.bias.data = torch.Tensor(b)\n",
        "    \n",
        "    self.linear2 = nn.Linear(2, 1, bias=False)\n",
        "    self.linear2.weight.data = torch.Tensor(v.T)\n",
        "    self.flatten = nn.Flatten(start_dim=1, end_dim=-1)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.pool = nn.MaxPool2d(kernel_size=(kernel_size, kernel_size), stride=stride)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, X):\n",
        "    Y = self.linear1(X)\n",
        "    Y = self.pool(self.relu(Y))\n",
        "    Y = self.linear2(self.flatten(Y))\n",
        "    Y = self.sigmoid(Y)\n",
        "    return Y"
      ],
      "metadata": {
        "id": "Oa0xGZNgz7bY"
      },
      "execution_count": 248,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_T = torch.Tensor([np.concatenate((X[:-(delta-1)], X[(delta-1):]), axis=1)])\n",
        "model = build_model(W, b, v, 2, 2)\n",
        "Y_T = model(X_T)"
      ],
      "metadata": {
        "id": "4BbKPtmgUBI7"
      },
      "execution_count": 249,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y = torch.Tensor([0])\n",
        "cost_func = nn.BCELoss()\n",
        "loss = cost_func(Y_T, Y)\n",
        "loss.backward()"
      ],
      "metadata": {
        "id": "FBd1IXpBtzs0"
      },
      "execution_count": 250,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Answer (7)\n",
        "v_grad = model.linear2.weight.grad.numpy()\n",
        "print('the gradient of the loss function with respect to v:\\n', v_grad)"
      ],
      "metadata": {
        "id": "rinqkZDYugUK",
        "outputId": "1b7b6a18-dc7a-41a0-fad6-e77958f80509",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 251,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the gradient of the loss function with respect to v:\n",
            " [1.  0.5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**(8)** Compute the gradients of the loss function with respect to $\\boldsymbol{W}$ for the training instance."
      ],
      "metadata": {
        "id": "CTt2o7hKz7zD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Answer (8)\n",
        "w_grad = model.linear1.weight.grad.numpy()\n",
        "print('the gradient of the loss function with respect to w:\\n', w_grad)"
      ],
      "metadata": {
        "id": "0mz0yeWF0PIy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f3d9eff-d584-464b-8647-468f251b8600"
      },
      "execution_count": 252,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the gradient of the loss function with respect to w:\n",
            " [[0.15 0.1  0.05 0.   0.05 0.1 ]\n",
            " [0.1  0.   0.1  0.   0.1  0.  ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 2 (20 points)\n",
        "\n",
        "Give names of two datasets that can be used to evaluate the quality of word embeddings, and explain the datasets with the following perspectives.\n",
        "\n",
        "+ Brief explanation of the task for the evaluation.\n",
        "+ Statistics of the dataset (e.g., the number of instances)\n",
        "+ Measure(s) for evaluating the quality"
      ],
      "metadata": {
        "id": "rPWwlW4F0P0i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "XdNBHor63biK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 3 (20 points)\n",
        "\n",
        "Explain two reasons why Transformers are superior to Recurrent Neural Network\n",
        "(RNN) in sequence-to-sequence tasks such as Machine Translation."
      ],
      "metadata": {
        "id": "xYrvAyBW3TxD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "CqfAdU713cYa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 4 (10 points)\n",
        "\n",
        "Implement the code for using a pre-trained **language** model. Show the code and its output as well as the following information:\n",
        "\n",
        "+ The detail of the pre-trained language model, for example,\n",
        "    + https://huggingface.co/EleutherAI/gpt-j-6B\n",
        "    + https://huggingface.co/rinna/japanese-gpt-1b\n",
        "    + https://huggingface.co/facebook/blenderbot-400M-distill\n",
        "+ The task addressed by the model (e.g., \"text generation\", \"summarization\", \"chatbot\")\n"
      ],
      "metadata": {
        "id": "YYxI86gA3dGs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "uCaAqhtCGC2I"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}