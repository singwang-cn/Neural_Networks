{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "aml2022_report.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/singwang-cn/Neural-Network/blob/master/aml2022_report.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Advanced Machine Learning (2022) Final Report Assignment\n",
        "\n",
        "Answer Questions 1 to 4 (either in Japanese or English). Submit a report in either PDF (.pdf) or JupyterNotebook (.ipynb) format.\n",
        "\n",
        "## Question 1 (50 points)\n",
        "\n",
        "Consider a convolutional neural network (CNN) that predicts a label $\\hat{y} \\in \\{0, 1\\}$ for a given sentence $\\boldsymbol{X} \\in \\mathbb{R}^{d \\times T}$. Here, a sentence is represented by a matrix $\\boldsymbol{X} = (\\boldsymbol{x}_1, \\boldsymbol{x}_2, \\dots, \\boldsymbol{x}_T)$ consisting of a concatenation of $T$ word embeddings, $\\boldsymbol{x}_1, \\boldsymbol{x}_2, \\dots, \\boldsymbol{x}_T \\in \\mathbb{R}^d$, where $d$ is the size of word embeddings, and $T$ is the number of words in the sentence.\n",
        "\n",
        "These equations define the whole architecture of the CNN.\n",
        "\n",
        "\\begin{align}\n",
        "\\hat{y} &= \\begin{cases}\n",
        "1 & (0.5 < p) \\\\\n",
        "0 & (p \\leq 0.5)\n",
        "\\end{cases} \\\\\n",
        "p &= \\sigma(\\boldsymbol{v}^\\top \\boldsymbol{s}) \\\\\n",
        "\\boldsymbol{s} &= \\max(\\boldsymbol{c}_1, \\dots, \\boldsymbol{c}_{T-\\delta+1}) \\\\\n",
        "\\boldsymbol{c}_t &= {\\rm ReLU}(\\boldsymbol{W} \\boldsymbol{x}_{t:t+\\delta-1} + \\boldsymbol{b}) & (\\forall t \\in \\{1, \\dots, T-\\delta+1\\}) \\\\\n",
        "\\boldsymbol{x}_{t:t+\\delta-1} &= \\boldsymbol{x}_{t} \\oplus \\boldsymbol{x}_{t+1} \\oplus \\dots \\oplus \\boldsymbol{x}_{t+\\delta-1}\n",
        "\\end{align}\n",
        "\n",
        "Here:\n",
        "\n",
        "+ $\\boldsymbol{W} \\in \\mathbb{R}^{m \\times \\delta d}$, $\\boldsymbol{b} \\in \\mathbb{R}^m, \\boldsymbol{v} \\in \\mathbb{R}^m$ are the model parameters;\n",
        "+ $m$ denotes the number of output channels of the CNN;\n",
        "+ $\\delta$ denotes the width (kernel size) of the convolution;\n",
        "+ $\\sigma(\\cdot)$ denotes the standard sigmoid function;\n",
        "+ $\\max(\\cdot)$ presents the max pooling operation;\n",
        "+ ${\\rm ReLU}(\\cdot)$ denotes the ReLU activation function;\n",
        "+ $\\oplus$ presents a concatenation of vectors.\n",
        "\n",
        "Setting the hyperparameters $d=3, m=2, \\delta=2$, we initialize the model parameters as follows.\n",
        "\n",
        "\\begin{align}\n",
        "\\boldsymbol{W} &= \\begin{pmatrix}\n",
        "-3 & -2 & -1 & -1 & -2 & -3 \\\\\n",
        "3 & 2 & 3 & 2 & 3 & 2\n",
        "\\end{pmatrix} \\\\\n",
        "\\boldsymbol{b} &= \\begin{pmatrix}\n",
        "-0.2 \\\\ 0.1\n",
        "\\end{pmatrix} \\\\\n",
        "\\boldsymbol{v} &= \\begin{pmatrix}\n",
        "-1 \\\\ 2\n",
        "\\end{pmatrix}\n",
        "\\end{align}\n",
        "\n",
        "Suppose that we give a negative ($y=0$) training instance with the sentence ($T = 5$),\n",
        "\n",
        "\\begin{align}\n",
        "\\boldsymbol{X} &= \\begin{pmatrix}\n",
        "-0.3 & 0 & 0.1 & 0 & 0 \\\\\n",
        "-0.2 & -0.1 & 0 & 0.1 & 0 \\\\\n",
        "-0.1 & -0.2 & 0.1 & 0 & 0.1\n",
        "\\end{pmatrix} ,\n",
        "\\end{align}\n",
        "to the CNN model, and answer the following questions.\n",
        "\n",
        "**(1)** Find the value of the vector $\\boldsymbol{x}_{3:4}$."
      ],
      "metadata": {
        "id": "-z-I39fBi1MD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "uec36GNAyNdz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**(2)** Find the values of the hidden vectors $\\boldsymbol{c}_1, \\boldsymbol{c}_2, \\boldsymbol{c}_3, \\boldsymbol{c}_4$."
      ],
      "metadata": {
        "id": "7XCf-KoPyOfp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "sgxmns3JyQgB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**(3)** Find the value of the vector $\\boldsymbol{s}$.\n"
      ],
      "metadata": {
        "id": "kVFqVPWPyQ58"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Vt3UQqqAyTVj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**(4)** Find the value of $p$."
      ],
      "metadata": {
        "id": "Kt26e_TSyT6W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "U4g6j4L3y635"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**(5)** Write the formula of the binary cross-entropy loss between the correct label $y$ and the probability estimate $p$."
      ],
      "metadata": {
        "id": "fUh6ZlAqyWRE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "QdCPWs4UyV9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**(6)** Compute the loss value by using the formula of (5) for the training instance."
      ],
      "metadata": {
        "id": "p9WQToWfyYuj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "LsFTKdK3zpYC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**(7)** Compute the gradient of the loss function with respect to $\\boldsymbol{v}$ for the training instance."
      ],
      "metadata": {
        "id": "6b03t2amzpz5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Oa0xGZNgz7bY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**(8)** Compute the gradients of the loss function with respect to $\\boldsymbol{W}$ for the training instance."
      ],
      "metadata": {
        "id": "CTt2o7hKz7zD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "0mz0yeWF0PIy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 2 (20 points)\n",
        "\n",
        "Give names of two datasets that can be used to evaluate the quality of word embeddings, and explain the datasets with the following perspectives.\n",
        "\n",
        "+ Brief explanation of the task for the evaluation.\n",
        "+ Statistics of the dataset (e.g., the number of instances)\n",
        "+ Measure(s) for evaluating the quality"
      ],
      "metadata": {
        "id": "rPWwlW4F0P0i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "XdNBHor63biK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 3 (20 points)\n",
        "\n",
        "Explain two reasons why Transformers are superior to Recurrent Neural Network\n",
        "(RNN) in sequence-to-sequence tasks such as Machine Translation."
      ],
      "metadata": {
        "id": "xYrvAyBW3TxD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "CqfAdU713cYa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 4 (10 points)\n",
        "\n",
        "Implement the code for using a pre-trained **language** model. Show the code and its output as well as the following information:\n",
        "\n",
        "+ The detail of the pre-trained language model, for example,\n",
        "    + https://huggingface.co/EleutherAI/gpt-j-6B\n",
        "    + https://huggingface.co/rinna/japanese-gpt-1b\n",
        "    + https://huggingface.co/facebook/blenderbot-400M-distill\n",
        "+ The task addressed by the model (e.g., \"text generation\", \"summarization\", \"chatbot\")\n"
      ],
      "metadata": {
        "id": "YYxI86gA3dGs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "uCaAqhtCGC2I"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}